{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis of Dr. Martin Luther King's (1963) \"I Have a Dream\" speech\n",
    "For more info on this speech, see https://en.wikipedia.org/wiki/I_Have_a_Dream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source & Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the file was read without error\n",
    "fp = open('MLK_I_Have_A_Dream.txt', 'r', encoding='ISO-8859-1')\n",
    "print(fp.readable()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell() provides current location of text file pointer\n",
    "fp.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seek(0) repositions file pointer to the begining of file; \n",
    "# seek(1) relative to current position; seek(2) relative to EOF\n",
    "# readline() prints one line in the file and moves pointer to next line\n",
    "fp.seek(0)\n",
    "print(fp.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put each line into an array and print array\n",
    "print(fp.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.seek(0)\n",
    "speech = fp.read()\n",
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the text is read into a variable, we can close the file pointer\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean/preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations and special characters\n",
    "for char in '!#$%&@?,.:;+-*/=<>\"\\'()[\\\\]{|}~\\n\\t':\n",
    "    speech = speech.replace(char, ' ')\n",
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = speech.lower()\n",
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "word_list = speech.split()\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [w for w in word_list if len(w) > 2]\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stopwords from NLTK\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk import corpus\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from corpus\n",
    "word_list = [w for w in word_list if w not in stop_words]\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to draw a barplot of the most frequent words in this speech\n",
    "# to do this, we must create a dictionary with word counts for each word, and sort the dictionary by word counts\n",
    "dict = {}                            # Initialize dictionary\n",
    "for w in word_list:\n",
    "    dict[w] = dict.get(w, 0) + 1\n",
    "# get() returns the value of a key (word) in a dictionary if it exists;\n",
    "# if the key is missing, it returns a value 0\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since dictionaries are unordered, to sort the word counts from high \n",
    "# to low, we must convert the dictionary into a list (of tuples)\n",
    "word_freq = []\n",
    "for key, value in dict.items():\n",
    "    word_freq.append((value, key))\n",
    "word_freq\n",
    "# items() returns a list of tuples with key-value pairs in a dictionary\n",
    "# Keys and values are reversed in list word_freq for ease of sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort word_freq list from high to low\n",
    "word_freq.sort(reverse=True)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_words = word_freq[0:20]\n",
    "top20_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the list of tuples to two tuples for plotting using zip()\n",
    "values, labels = zip(*top20_words)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot of most frequent words\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(labels, values)\n",
    "plt.xlabel('Words')\n",
    "plt.xticks(rotation=65)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Barplot of Top 20 Most Frequent Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud\n",
    "Install the wordcloud library from Anaconda command prompt (Note: The \"python -m\" option ensures compatibility with current Python kernel).\n",
    "\n",
    "python -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wordcloud on Anaconda command prompt; WordCloud requires a text corpus as input\n",
    "# python -m pip install wordcloud\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "text_corpus = ' '.join(word_list)\n",
    "wordcloud = WordCloud(width=500, height=500, background_color='white', collocations='FALSE', min_font_size=16).generate(text_corpus)\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How is it that \"freedom\" is the most frequent word in the barplot, but appears in smaller font in the word cloud?\n",
    "\n",
    "Ans: By default, wordcloud uses bigrams, which treats \"freedom\" and \"let freedom\" as two bigrams, and reduces the frequency of the word freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create n-grams using NLTK\n",
    "# n-grams is a way of preserving sequence (and meaning) of words\n",
    "from nltk.util import ngrams\n",
    "word_list = speech.split()\n",
    "bigrams = list(ngrams(word_list, 4))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = list(ngrams(word_list, 3))\n",
    "trigrams = [' '.join(word) for word in trigrams]\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(analyzer.polarity_scores(speech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analyzer.polarity_scores(text_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in word_list:\n",
    "    print(w, analyzer.polarity_scores(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = 0\n",
    "positive_words = 0\n",
    "pol_words = 0\n",
    "sum_pol = 0.0\n",
    "\n",
    "for w in word_list:\n",
    "    pol = analyzer.polarity_scores(w)\n",
    "    if pol[\"compound\"] != 0:\n",
    "        pol_words += 1\n",
    "        sum_pol = sum_pol + pol[\"compound\"]\n",
    "    if pol[\"neg\"] > 0:\n",
    "        negative_words += 1 \n",
    "    if pol[\"pos\"] > 0:\n",
    "        positive_words += 1\n",
    "        \n",
    "print(\"Positive words: \", positive_words)\n",
    "print(\"Negative words: \", negative_words)\n",
    "print(\"Polarity \", sum_pol/pol_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what have we learned from the above analysis of Dr. MLK's \"I Have a Dream\" speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
