{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String, Lists, and Regular Expressions\n",
    "Python provides two ways to process text: strings and lists. \n",
    "We will use various string functions such as lower(), append(), split(), and strip(), and Python's RE (regular expression) library.\n",
    "### Strings:\n",
    "Strings are delimited using ', \", or even ''' (triple quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York, New York (So Good They Named It Twice)\n"
     ]
    }
   ],
   "source": [
    "text = 'New York, New York (So Good They Named It Twice)'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "one\n",
      "two \n",
      "three\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiline strings are denoted using triple-quotes \n",
    "multiline = \"\"\"\n",
    "one\n",
    "two \n",
    "three\n",
    "\"\"\"\n",
    "print(multiline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york, new york (so good they named it twice)\n"
     ]
    }
   ],
   "source": [
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW YORK, NEW YORK (SO GOOD THEY NAMED IT TWICE)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York, New York (So Good They Named It Twice)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New york, new york (so good they named it twice)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nEW yORK, nEW yORK (sO gOOD tHEY nAMED iT tWICE)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck = \"    If it looks like a duck,     swims like a duck, and     quacks like a duck, then it is    probably a duck.  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If it looks like a duck,     swims like a duck, and     quacks like a duck, then it is    probably a duck.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    If it looks like a duck,     swims like a duck, and     quacks like a duck, then it is    probably a duck.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If it looks like a duck,     swims like a duck, and     quacks like a duck, then it is    probably a duck.  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To locate first occurrence of a character string: str.find() or str.index()\n",
    "duck.find(\"duck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfind() or rindex() works from end of string\n",
    "duck.rfind(\"duck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns -1 if search string is not found\n",
    "duck.find(\"fox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if a substring occurs at the begining (or end) of a string\n",
    "duck.startswith(\"duck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck.strip().endswith(\"duck.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    If it looks like a chicken,     swims like a chicken, and     quacks like a chicken, then it is    probably a chicken.  '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck.replace(\"duck\", \"chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If it l----ks like a duck,     swims like a duck, and     quacks like a duck, then it is    pr--bably a duck.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck = \"    If it looks like a duck,     swims like a duck, and     quacks like a duck, then it is    probably a duck.  \"\n",
    "duck.strip().replace(\"o\", \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('    If it looks like a ',\n",
       " 'duck',\n",
       " ',     swims like a duck, and     quacks like a duck, then it is    probably a duck.  ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting a string based on a substring location\n",
    "duck.partition(\"duck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'a',\n",
       " 'duck,',\n",
       " 'swims',\n",
       " 'like',\n",
       " 'a',\n",
       " 'duck,',\n",
       " 'and',\n",
       " 'quacks',\n",
       " 'like',\n",
       " 'a',\n",
       " 'duck,',\n",
       " 'then',\n",
       " 'it',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'a',\n",
       " 'duck.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting a string into a list of words\n",
    "duck.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: split() removes blank spaces, but does not remove punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'one', 'two ', 'three']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting a multi-line document based on newline characters\n",
    "multiline.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If--it--looks--like--a--duck,--swims--like--a--duck,--and--quacks--like--a--duck,--then--it--is--probably--a--duck.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining words in a list back to a string\n",
    "words = duck.split()\n",
    "\"--\".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"--\" in the above example is an iterable; you can use a space here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If\\nit\\nlooks\\nlike\\na\\nduck,\\nswims\\nlike\\na\\nduck,\\nand\\nquacks\\nlike\\na\\nduck,\\nthen\\nit\\nis\\nprobably\\na\\nduck.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining with newline to a multi-line string\n",
    "\"\\n\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If\n",
      "it\n",
      "looks\n",
      "like\n",
      "a\n",
      "duck,\n",
      "swims\n",
      "like\n",
      "a\n",
      "duck,\n",
      "and\n",
      "quacks\n",
      "like\n",
      "a\n",
      "duck,\n",
      "then\n",
      "it\n",
      "is\n",
      "probably\n",
      "a\n",
      "duck.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting strings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists: \n",
    "Another way to store text. This is a \"Bag of words\" model; text is unordered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'it', 'looks', 'like', 'a', 'duck,', 'swims', 'like', 'a', 'duck,', 'and', 'quacks', 'like', 'a', 'duck,', 'then', 'it', 'is', 'probably', 'a', 'duck.']\n"
     ]
    }
   ],
   "source": [
    "words = duck.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duck,like'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[5] + words[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If', 'it']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duck.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = ['awesome', 'good', 'nice', 'super', 'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome', 'good', 'nice', 'super', 'like', 'delightful']\n"
     ]
    }
   ],
   "source": [
    "positive_words.append('delightful')\n",
    "print(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awful', 'lame', 'horrible', 'bad']\n"
     ]
    }
   ],
   "source": [
    "negative_words = ['awful','lame','horrible','bad']\n",
    "print(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awful', 'lame', 'horrible', 'bad', 'awesome', 'good', 'nice', 'super', 'like', 'delightful']\n"
     ]
    }
   ],
   "source": [
    "# Combining lists\n",
    "emotional_words = negative_words + positive_words\n",
    "print(emotional_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuples & Dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 'fish')\n"
     ]
    }
   ],
   "source": [
    "# Tuple: immutable lists, indicated by parentheses\n",
    "row = (1, 3, \"fish\")\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Cat in the Hat', 'author': 'Dr. Seuss', 'Year': 1957}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary: key:value pairs\n",
    "book = {'title': 'Cat in the Hat', 'author': 'Dr. Seuss', 'Year': 1957}\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'have', 'some', 'delightful', 'new', 'food', 'in', 'the', 'cafeteria.', 'Awesome!!!']\n"
     ]
    }
   ],
   "source": [
    "# Splitting a string into a set of words is called TOKENIZATION\n",
    "\n",
    "tweet1 = 'We have some delightful new food in the cafeteria. Awesome!!!'\n",
    "words1 = tweet1.split()\n",
    "print(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "have\n",
      "some\n",
      "delightful\n",
      "new\n",
      "food\n",
      "in\n",
      "the\n",
      "cafeteria.\n",
      "Awesome!!!\n"
     ]
    }
   ],
   "source": [
    "for word in words1:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delightful\n"
     ]
    }
   ],
   "source": [
    "for word in words1:\n",
    "    if word in positive_words:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"awesome\" was not detected because it was not an exact character match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+\n"
     ]
    }
   ],
   "source": [
    "tweet2 = \"Food is lame today. I don't like it at all\"\n",
    "words2 = tweet2.split()\n",
    "\n",
    "for word in words2:\n",
    "    if word in positive_words:\n",
    "        print('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "+\n"
     ]
    }
   ],
   "source": [
    "for word in words2:\n",
    "    if word in positive_words:\n",
    "        print ('+')\n",
    "    elif word in negative_words:\n",
    "        print ('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, lame (-) occurs first, followed by like (+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lame is a negative word.\n",
      "like is a positive word.\n"
     ]
    }
   ],
   "source": [
    "for word in words2:\n",
    "    if word in positive_words:\n",
    "        print (word + ' is a positive word.')\n",
    "    elif word in negative_words:\n",
    "        print (word + \" is a negative word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14159 3.14159\n"
     ]
    }
   ],
   "source": [
    "pi = 3.14159\n",
    "print(pi, str(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (<ipython-input-45-cf4ea36d4e3f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-cf4ea36d4e3f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print('pi = ' + pi))\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "print('pi = ' + pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is a number.\n",
      "2 is a number.\n",
      "4 is a number.\n",
      "like is a number.\n",
      "8 is a number.\n"
     ]
    }
   ],
   "source": [
    "for number in [1, 2, 4, 'like', 8]:\n",
    "    sentence = str(number) + ' is a number.'\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is written in Python\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "string = \"This article is written in {}\"\n",
    "print (string.format(\"Python\")) \n",
    "print(\"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am 21 years old!\n"
     ]
    }
   ],
   "source": [
    "age = 21\n",
    "print(\"Hello, I am {} years old!\".format(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm 21 years old, and a business analytics major.\n"
     ]
    }
   ],
   "source": [
    "# multiple placeholders\n",
    "major = 'business analytics'\n",
    "print(\"I'm {} years old, and a {} major.\".format(age, major))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm 21 years old, and a business analytics major.\n"
     ]
    }
   ],
   "source": [
    "# positional arguments\n",
    "print(\"I'm {1} years old, and a {0} major.\".format(major, '21'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature today is 35.567000 degrees outside!\n"
     ]
    }
   ],
   "source": [
    "''' Specifying types: \n",
    "s â€“ strings\n",
    "d â€“ decimal integers\n",
    "f â€“ floating point numbers\n",
    "c â€“ character\n",
    "b â€“ binary\n",
    "o â€“ octal\n",
    "x â€“ hexadecimal with lowercase letters after 9\n",
    "X â€“ hexadecimal with uppercase letters after 9\n",
    "e â€“ exponent notation\n",
    "'''\n",
    "\n",
    "print(\"The temperature today is {0:f} degrees outside!\".format(35.567))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature today is 36 degrees outside !\n"
     ]
    }
   ],
   "source": [
    "print(\"The temperature today is {0:.0f} degrees outside !\".format(35.567))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average grade in the text analytics class was 78.23%\n"
     ]
    }
   ],
   "source": [
    "print (\"The average grade in the {0} class was {1:.2f}%\".format(\"text analytics\", 78.234876)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary of 100 is 1100100\n"
     ]
    }
   ],
   "source": [
    "print(\"The {0} of 100 is {1:b}\".format(\"binary\", 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is    40 degrees outside !\n"
     ]
    }
   ],
   "source": [
    "# Adjusting for spacing\n",
    "print(\"It is {0:5} degrees outside !\".format(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3      9     27     81\n",
      "     4     16     64    256\n",
      "     5     25    125    625\n",
      "     6     36    216   1296\n",
      "     7     49    343   2401\n",
      "     8     64    512   4096\n"
     ]
    }
   ],
   "source": [
    "for i in range (3, 9): \n",
    "    print(\"{:6d} {:6d} {:6d} {:6d}\".format(i, i**2, i**3, i**4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have some delightful new food in the cafeteria. awesome!!!\n"
     ]
    }
   ],
   "source": [
    "tweet1 = \"We have some delightful new food in the cafeteria. Awesome!!!\"\n",
    "print (tweet1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'have', 'some', 'delightful', 'new', 'food', 'in', 'the', 'cafeteria.', 'awesome!!!']\n"
     ]
    }
   ],
   "source": [
    "words1 = tweet1.lower().split()\n",
    "print (words1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lower() works with strings; not with lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome\n"
     ]
    }
   ],
   "source": [
    "print('Awesome!!!'.strip('!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = punctuation + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Awesome'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Awesome!!!\".strip(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Awesome party'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Awesome!!! party\".replace(\"!\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have some delightful new food in the cafeteria. Awesome!!!\n",
      "we have some delightful new food in the cafeteria. awesome\n"
     ]
    }
   ],
   "source": [
    "print(tweet1)\n",
    "tweet1 = tweet1.lower().strip(punctuation)\n",
    "print(tweet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did not remove the period! We have to remove it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have some delightful new food in the cafeteria awesome\n"
     ]
    }
   ],
   "source": [
    "tweet1 = tweet1.replace(\".\", \"\")\n",
    "print(tweet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'have', 'some', 'delightful', 'new', 'food', 'in', 'the', 'cafeteria', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "words1 = tweet1.split()\n",
    "print(words1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " 'have',\n",
       " 'some',\n",
       " 'delightful',\n",
       " 'new',\n",
       " 'food',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cafeteria',\n",
       " 'awesome']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet1 = 'We have some delightful new food in the cafeteria. Awesome!!!'\n",
    "words1 = tweet1.lower().strip(punctuation).replace(\".\", \"\").split()\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'good', 'nice', 'super', 'like', 'delightful']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awful', 'lame', 'horrible', 'bad']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have some delightful new food in the cafeteria. Awesome!!!\n",
      "Positive word count: 2\n",
      "Negative word count: 0\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "negative = 0\n",
    "for word in words1:\n",
    "    if word in positive_words:\n",
    "        positive += 1\n",
    "    elif word in negative_words:\n",
    "        negative += 1\n",
    "\n",
    "print (tweet1 + \"\\nPositive word count: \" + str(positive) \n",
    "       + \"\\nNegative word count: \" + str(negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score: 1.0\n"
     ]
    }
   ],
   "source": [
    "sentiment = (positive - negative)/(positive + negative)\n",
    "print(\"Sentiment score: \" + str(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food is lame today. I don't like it at all\n",
      "Positive word count: 1\n",
      "Negative word count: 1\n",
      "Sentiment score: 0.0\n"
     ]
    }
   ],
   "source": [
    "tweet2 = \"Food is lame today. I don't like it at all\"\n",
    "words2 = tweet2.lower().strip(punctuation).replace(\".\", \"\").split()\n",
    "print(tweet2)\n",
    "\n",
    "positive = 0\n",
    "negative = 0\n",
    "for word in words2:\n",
    "    if word in positive_words:\n",
    "        positive += 1\n",
    "    elif word in negative_words:\n",
    "        negative += 1\n",
    "sentiment = (positive - negative)/(positive + negative)\n",
    "\n",
    "print (\"Positive word count: \" + str(positive))\n",
    "print (\"Negative word count: \" + str(negative))\n",
    "print(\"Sentiment score: \" + str(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The above code ignored \"don't\" because it is not in the \"bag of words\". It is very important to have a comprehensive bag of words if you want to do a word-based sentiment analysis. It is also important to consider bigrams (e.g., \"don't like\") to get a proper semantic interpretation.\n",
    "\n",
    "This was a very crude and incomplete sentiment analysis. The adequacy of the analysis depends on the completeness of the corpus of positive and negative words and also the algorithm's ability to detect negation. LIWC is the industry standard corpus for sentiment analysis. But LIWC is not free. A free and somewhat extensive corpus for sentiment analysis is Hu & Liu's (2004) Sentiment Lexicon that you can download from here: https://github.com/woodrad/Twitter-Sentiment-Mining/tree/master/Hu%20and%20Liu%20Sentiment%20Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regular Expressions\n",
    "Allows wildcard matching and many complex string operations (. is single character, + is many characters)<br>\n",
    "Reference: E.F. Friedlâ€™s Mastering Regular Expressions (3rd Edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\s is a special character that matches any whitespace (space, tab, newline, etc.), and the \"+\" is a character that indicates one or more of the entity preceding it. Thus, the regular expression matches any substring consisting of one or more spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'a', 'lazy', 'dog.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox = \"The quick    brown   fox jumped over a lazy dog.\"\n",
    "regex.split(fox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex.search() method is similar to str.index() or str.find(); \n",
    "# locates substring position. re.compile() specifies search string.\n",
    "regex = re.compile(\"dog\")\n",
    "match = regex.search(fox)\n",
    "match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick    brown   fox jumped over a lazy bear.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex.sub() method operates much like str.replace()\n",
    "fox.replace('dog', 'bear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ion']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex.findall() is similar to str.find()\n",
    "regex = re.compile('ion')\n",
    "regex.findall('Great Expectations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain characters have special meanings in regular expressions:\n",
    ". ^ $ * + ? { } [ ] \\ | ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tb\tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['$']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r in r'\\$' indicates a raw string (always use it before a \\)\n",
    "# \\ indicate special characters, e.g. \"\\t\"\n",
    "print('a\\tb\\tc')\n",
    "regex = re.compile(r'\\$')\n",
    "regex.findall(\"the cost is $20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e f', 'x i', 's 9', 's o']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\w is alphanumeric character string; \\s is space\n",
    "regex = re.compile(r'\\w\\s\\w')\n",
    "regex.findall('the fox is 9 years old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'ns', 'q', '', 'nt', '', 'l']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square brackets denote any set of characters\n",
    "regex = re.compile('[aeiou]')\n",
    "regex.split('consequential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G2', 'H6']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A range can be specified with a dash: \n",
    "# [a-z]: any lower-case letter' [1-3]: Any number between 1 and 3\n",
    "regex = re.compile('[A-Z][0-9]')\n",
    "regex.findall('1043879, G2, H6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'qui', 'bro', 'fox']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To match 3 alphanumeric characters in sequence, you can use \"\\w\\w\\w\" or \n",
    "# indicate repetitions using curly braces with a number\n",
    "regex = re.compile(r'\\w{3}')\n",
    "regex.findall('The quick brown fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The + character will match one or more repetitions of what precedes it\n",
    "regex = re.compile(r'\\w+')\n",
    "regex.findall('The quick brown fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guido@python.org', 'guido@google.com']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching e-mail addresses\n",
    "text = \"To contact Guido, e-mail guido@python.org or his older address guido@google.com.\"\n",
    "email = re.compile('\\w+@\\w+\\.[a-z]{3}')\n",
    "email.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barack.obama@whitehouse.gov']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above technique may not work for more complex e-mail addresses\n",
    "\n",
    "email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "email.findall('barack.obama@whitehouse.gov')\n",
    "# Extracts strings of the pattern: [alphanumeric character (\\w), period (\\.), or hyphen(-)] \n",
    "# multiple times (+), followed by @, followed by [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guido', 'python', 'org'), ('guido', 'google', 'com')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parentheses indicate groups to extract\n",
    "email = re.compile(r'([\\w.]+)@(\\w+)\\.([a-z]{3})')\n",
    "text = \"To contact Guido, e-mail guido@python.org or his older address guido@google.com.\"\n",
    "email.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different Types of Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if', 'it', 'looks', 'like', 'a', 'duck,', 'swims', 'like', 'a', 'duck,', 'and', 'quacks', 'like', 'a', 'duck,', 'then', 'it', 'is', 'probably', 'a', 'duck.']\n"
     ]
    }
   ],
   "source": [
    "string = \"If it LOOKS like a duck, SWIMS like a duck, and QUACKS like a duck, then it is probably a duck.\"\n",
    "print(string.lower().split())                      # Retains adjacent punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'it', 'LOOKS', 'like', 'a', 'duck,', 'SWIMS', 'like', 'a', 'duck,', 'and', 'QUACKS', 'like', 'a', 'duck,', 'then', 'it', 'is', 'probably', 'a', 'duck.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.split('\\s', string))                      # Can use any string as separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'it', 'LOOKS', 'like', 'a', 'duck', ',', 'SWIMS', 'like', 'a', 'duck', ',', 'and', 'QUACKS', 'like', 'a', 'duck', ',', 'then', 'it', 'is', 'probably', 'a', 'duck', '.']\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(string))                       # Separates punctuations into independent strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi, Sam.', 'How are you today?', 'I like your shoes.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "string = 'Hi, Sam. How are you today? I like your shoes.'\n",
    "print(sent_tokenize(string))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi, Sam', ' How are you today', ' I like your shoes', '']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "print(re.split(r\"[.!?]\", string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[\"This is the best #nlp exercise I've found online! #python\",\n",
    " \"#NLP is super fun! <3 #learning\",\n",
    " \"Thanks @pythonworkshop :) #nlp #python\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#nlp', '#python']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "regexp_tokenize(tweets[0], r\"#\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@pythonworkshop', '#nlp', '#python']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(tweets[-1], r\"([#|@]\\w+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'the', 'best', '#nlp', 'exercise', \"I've\", 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@pythonworkshop', ':)', '#nlp', '#python']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "all_tokens = [tokenizer.tokenize(t) for t in tweets]\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Best Pizza in town! ðŸ• Want to take a Uber? ðŸš•\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best', 'Pizza', 'Want', 'Uber']\n"
     ]
    }
   ],
   "source": [
    "print(regexp_tokenize(tweet, r\"[A-Z]\\w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸ•', 'ðŸš•']\n"
     ]
    }
   ],
   "source": [
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(tweet, emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
